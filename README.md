Build a Facebook Messenger Chatbot Admin Dashboard
Goal

Create a secure, production-ready web app where an admin can:

Connect a Facebook Page (Messenger)

Configure an LLM provider (OpenAI / Gemini / OpenRouter)

Monitor conversations in real time and reply manually

Enable/disable the chatbot per message or per conversation

Tech Stack

Frontend: Next.js 14 (App Router), TypeScript, Tailwind, shadcn/ui, React Query (TanStack Query)

Auth: NextAuth (Email + OAuth as needed)

Backend: Next.js API routes / Route Handlers, TypeScript

DB: PostgreSQL + Prisma ORM

Cache/Queue: Redis (BullMQ) for outbound message queue and webhook processing

Realtime: Socket.IO (or Pusher-compatible adapter). Prefer Socket.IO self-host for control.

Secrets: Store encrypted at rest (Prisma field-level encryption or KMS; at minimum encrypt before DB)

Deployment: Vercel (frontend) + Fly.io/Render for long-running workers, or all on a single VPS/VM with PM2

Logging/Obs: pino logs, OpenTelemetry hooks, Sentry for error tracking

Core Features

1. Auth & RBAC

Roles: OWNER, ADMIN, AGENT

Only OWNER/ADMIN can manage settings, connections, providers.

Agents can view/handle chats and toggle bot per message/conversation.

2. Settings

LLM Provider: radio/select for OpenAI | Gemini | OpenRouter

Inputs: API Key (masked), model name (dropdown + free text), temperature, max tokens, system prompt.

Facebook Page Connection

OAuth/Connect flow to obtain: page_id, page_access_token, webhook verification.

Webhook subscribe/unsubscribe buttons with status indicator.

Security: Keys stored encrypted; never returned in plaintext after save.

3. Real-time Inbox

Conversation list (left): latest message preview, unread count, online indicator.

Chat view (center): message bubbles with:

Sender (User vs Page), timestamps, delivery markers.

Per-message toggle: “Reply as Bot” switch next to composer. When ON, the next outgoing reply is generated by the configured LLM; when OFF, human message from admin.

Per-conversation toggle (toolbar): “Auto-bot mode” (all inbound messages trigger bot reply automatically until disabled).

Composer:

Text input, send button, attachment stub (non-blocking).

Quick action: “Generate draft with AI” (one-off LLM call, editable before sending).

Side panel (right): Contact profile (name, PSID, locale, conversation notes), conversation tags, assignee, internal notes.

4. Bot Orchestration

System prompt template with variables: brand name, tone, do/don’t list.

Safety guardrails: profanity filter, max # bot messages in a row (e.g., 3), confidence fallback to human.

Memory: per conversation short-term summary stored server-side; include last N turns in prompt.

Handoff: if user asks for human, automatically disable auto-bot mode.

5. Logs & Analytics

Message log table (filter by page, agent, time range).

Bot performance: response count, avg latency, deflection rate (no human follow-up needed), handoffs.

Webhook health: last event time, failures, retry counts.

Data Model (Prisma)
model User {
id String @id @default(cuid())
email String @unique
name String?
role Role @default(AGENT)
Sessions Session[]
Company Company? @relation(fields: [companyId], references: [id])
companyId String?
createdAt DateTime @default(now())
}

enum Role { OWNER ADMIN AGENT }

model Company {
id String @id @default(cuid())
name String
pages PageConnection[]
providerConfig ProviderConfig?
users User[]
createdAt DateTime @default(now())
}

model ProviderConfig {
id String @id @default(cuid())
company Company @relation(fields: [companyId], references: [id])
companyId String @unique
provider Provider @default(OPENAI)
apiKeyEnc String // ciphertext
model String
temperature Float @default(0.3)
maxTokens Int @default(512)
systemPrompt String @default("You are a helpful, brand-safe support assistant...")
}

enum Provider { OPENAI GEMINI OPENROUTER }

model PageConnection {
id String @id @default(cuid())
company Company @relation(fields: [companyId], references: [id])
companyId String
pageId String @unique
pageName String
pageAccessTokenEnc String // ciphertext
verifyTokenEnc String // ciphertext for webhook verification
subscribed Boolean @default(false)
createdAt DateTime @default(now())
}

model Conversation {
id String @id @default(cuid())
page PageConnection @relation(fields: [pageId], references: [id])
pageId String
psid String // Messenger user ID
status ConvStatus @default(OPEN)
autoBot Boolean @default(false)
lastMessageAt DateTime @default(now())
messages Message[]
assigneeId String?
notes String?
tags String[] @default([])
createdAt DateTime @default(now())
}

enum ConvStatus { OPEN SNOOZED CLOSED }

model Message {
id String @id @default(cuid())
conversation Conversation @relation(fields: [conversationId], references: [id])
conversationId String
role MsgRole // USER | AGENT | BOT
text String
providerUsed Provider?
meta Json?
createdAt DateTime @default(now())
}

enum MsgRole { USER AGENT BOT }

API Routes (Next.js Route Handlers)

POST /api/auth/webhook/facebook

Verify via hub.mode|challenge|verify_token (GET)

Receive message events (POST). Parse and enqueue jobs (Redis).

POST /api/messages/send

Body: { conversationId, text, sendAs: "AGENT"|"BOT" }

If BOT, call LLM first to generate text; then enqueue Messenger send job. Persist Message rows for both draft and final.

POST /api/conversations/:id/toggle-auto-bot

GET /api/conversations (paginated, filters)

GET /api/conversations/:id/messages (paginated)

POST /api/settings/provider (create/update, encrypt key)

POST /api/settings/page/connect (store tokens, encrypt; set subscribed)

POST /api/settings/page/subscribe (subscribe app to page; FB Graph API)

GET /api/logs (admin)

Return JSON with clear error codes. Use Zod for input validation.

Workers & Realtime

Worker (BullMQ) jobs:

incoming:fb_message → upsert conversation, persist user message, emit socket event message:new. If conversation.autoBot is true, schedule bot:reply.

bot:reply → fetch recent N messages, construct prompt, call provider, persist bot message, enqueue outgoing:fb_message.

outgoing:fb_message → call FB Send API, retry with backoff on 4xx/5xx.

Socket events:

conversation:updated, message:new, presence:update

Auth guard: join rooms by conversationId only if user has access.

Facebook Integration (Graph API)

Webhook verification (GET) with stored verify token.

Receive message object (POST) for messaging events.

Send API: POST /{PAGE_ID}/messages with page_access_token.

Handle standby/take thread control if you later add Handover Protocol (optional).

Store minimal PII and allow deletion upon request.

LLM Provider Abstraction

Interface:

type LLMRequest = { model: string; temperature: number; maxTokens: number; systemPrompt: string; messages: {role: "system"|"user"|"assistant"; content: string;}[] }
type LLMResponse = { text: string; usage?: any }

Implement adapters:

OpenAI (Responses API or Chat Completions)

Google Gemini (generative-language)

OpenRouter (standard OpenAI-compatible)

Include safety: max chain length, profanity regex, refusal patterns → fallback to human.

UI Pages

/login

/dashboard

Left: search + conversation list (filters: open/closed/unread, page, tag)

Center: chat thread, composer, toggle “Reply as Bot” for the next reply

Top bar: per-conversation Auto-bot toggle + status badges

Right: contact profile, notes, tags, assignee

/settings

Provider: provider select, API key (masked), model, temperature, system prompt

Facebook: connect page, show connection status, webhook status (green/red), subscribe/unsubscribe

/logs & /analytics (admin only)

Security & Compliance

Encrypt provider and page tokens (libsodium sealed boxes or KMS). Mask on read.

CSRF protection for mutating routes, strict CORS.

Rate limit outbound LLM & FB sends per company.

Audit log for settings changes.

PII minimization and deletion endpoint.

Testing

Unit tests: adapters, prompt builder, webhook parser.

Integration tests: webhook → DB → socket flow, send API mocks.

E2E (Playwright): connect dummy page, simulate incoming messages.

Env Vars
DATABASE_URL=
REDIS_URL=
NEXTAUTH_SECRET=
NEXTAUTH_URL=
ENCRYPTION_KEY= # 32-byte base64
FB_APP_ID=
FB_APP_SECRET=
WEBHOOK_VERIFY_TOKEN=
OPENAI_API_KEY=
GEMINI_API_KEY=
OPENROUTER_API_KEY=

Seed & Demo

Script to create demo company, user (OWNER), and fake conversations/messages.

Mock webhook receiver for local dev.

Acceptance Criteria

Admin can connect a FB Page, verify webhook, and receive live messages.

Real-time inbox updates on new messages without refresh.

Per-message “Reply as Bot” works (one-off generation).

Per-conversation “Auto-bot mode” works and can be toggled anytime.

Provider can be switched among OpenAI/Gemini/OpenRouter without code changes.

Secrets are encrypted at rest; API keys are never returned in plaintext.

Deliverables

Monorepo (apps/web, packages/core, workers/queue)

README with setup, FB webhook instructions, and local testing

Example .env.example populated

Seed script and minimal sample tests

Optional: System Prompt Template for the Bot

You are {brand_name}’s support assistant on Facebook Messenger. Be concise, helpful, and friendly.
Do not hallucinate policies or prices—if unsure, ask clarifying questions or handoff to a human.
Respect these rules:

Never share internal details or API keys.

Keep answers under 3 short paragraphs.

If the user asks for a human or indicates frustration, stop and set handoff=true.

Use the following FAQs and policies if relevant: {policy_snippets}.
Conversation summary: {short_memory}.
Recent messages: {last_n_messages}."
